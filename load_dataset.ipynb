{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:19.265866Z",
     "start_time": "2025-01-17T09:06:18.273210Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import logging\n",
    "import sys\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:20.723231Z",
     "start_time": "2025-01-17T09:06:19.273874Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_test = load_dataset(\"wikitablequestions\", trust_remote_code=True)",
   "id": "28604ee587ecdf84",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:20.985235Z",
     "start_time": "2025-01-17T09:06:20.982921Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset_test)",
   "id": "1b243d8a941a18cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 11321\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 4344\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 2831\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:21.058082Z",
     "start_time": "2025-01-17T09:06:21.054722Z"
    }
   },
   "cell_type": "code",
   "source": "train, test, eval = dataset_test['train'], dataset_test['test'], dataset_test['validation']",
   "id": "208ecb5de4c8ac20",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:23.078004Z",
     "start_time": "2025-01-17T09:06:21.125526Z"
    }
   },
   "cell_type": "code",
   "source": "train['table'][0]",
   "id": "93cd71ea14368f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': ['Year',\n",
       "  'Division',\n",
       "  'League',\n",
       "  'Regular Season',\n",
       "  'Playoffs',\n",
       "  'Open Cup',\n",
       "  'Avg. Attendance'],\n",
       " 'rows': [['2001',\n",
       "   '2',\n",
       "   'USL A-League',\n",
       "   '4th, Western',\n",
       "   'Quarterfinals',\n",
       "   'Did not qualify',\n",
       "   '7,169'],\n",
       "  ['2002',\n",
       "   '2',\n",
       "   'USL A-League',\n",
       "   '2nd, Pacific',\n",
       "   '1st Round',\n",
       "   'Did not qualify',\n",
       "   '6,260'],\n",
       "  ['2003',\n",
       "   '2',\n",
       "   'USL A-League',\n",
       "   '3rd, Pacific',\n",
       "   'Did not qualify',\n",
       "   'Did not qualify',\n",
       "   '5,871'],\n",
       "  ['2004',\n",
       "   '2',\n",
       "   'USL A-League',\n",
       "   '1st, Western',\n",
       "   'Quarterfinals',\n",
       "   '4th Round',\n",
       "   '5,628'],\n",
       "  ['2005',\n",
       "   '2',\n",
       "   'USL First Division',\n",
       "   '5th',\n",
       "   'Quarterfinals',\n",
       "   '4th Round',\n",
       "   '6,028'],\n",
       "  ['2006',\n",
       "   '2',\n",
       "   'USL First Division',\n",
       "   '11th',\n",
       "   'Did not qualify',\n",
       "   '3rd Round',\n",
       "   '5,575'],\n",
       "  ['2007',\n",
       "   '2',\n",
       "   'USL First Division',\n",
       "   '2nd',\n",
       "   'Semifinals',\n",
       "   '2nd Round',\n",
       "   '6,851'],\n",
       "  ['2008',\n",
       "   '2',\n",
       "   'USL First Division',\n",
       "   '11th',\n",
       "   'Did not qualify',\n",
       "   '1st Round',\n",
       "   '8,567'],\n",
       "  ['2009',\n",
       "   '2',\n",
       "   'USL First Division',\n",
       "   '1st',\n",
       "   'Semifinals',\n",
       "   '3rd Round',\n",
       "   '9,734'],\n",
       "  ['2010',\n",
       "   '2',\n",
       "   'USSF D-2 Pro League',\n",
       "   '3rd, USL (3rd)',\n",
       "   'Quarterfinals',\n",
       "   '3rd Round',\n",
       "   '10,727']],\n",
       " 'name': 'csv/204-csv/590.tsv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:06:28.666158Z",
     "start_time": "2025-01-17T09:06:26.852869Z"
    }
   },
   "cell_type": "code",
   "source": "print(str(train['table'][0]))",
   "id": "9023d1a57cad2d14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header': ['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], 'rows': [['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']], 'name': 'csv/204-csv/590.tsv'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:21:46.819127Z",
     "start_time": "2025-01-16T22:21:46.805482Z"
    }
   },
   "cell_type": "code",
   "source": "train['question'][0]",
   "id": "b4d73b131e58f17e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what was the last year where this team was a part of the usl a-league?'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:21:46.882960Z",
     "start_time": "2025-01-16T22:21:46.845831Z"
    }
   },
   "cell_type": "code",
   "source": "train['answers'][0]",
   "id": "f3b071da9c9d8440",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2004']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:24:08.414158Z",
     "start_time": "2025-01-16T22:24:08.411280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def concat_str(table: dict, question: str, answers: list, mode='train') -> str:\n",
    "    target_str = ''\n",
    "    target_str += 'Table: | '\n",
    "    target_str += ' '.join(table['header'])\n",
    "    target_str += ' | '\n",
    "    \n",
    "    target_str += ' | '.join([' '.join(row) for row in table['rows']])\n",
    "    target_str += ' |'\n",
    "    target_str += '\\tQuestion:'\n",
    "    target_str += f' {question}\\t'\n",
    "    if mode == 'train':\n",
    "        target_str += 'Answers: '\n",
    "        target_str += ' | '\n",
    "        target_str += ' | '.join(answers)\n",
    "        target_str += ' |'\n",
    "    \n",
    "    return target_str"
   ],
   "id": "1eab08bc0a3e027c",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:24:11.808887Z",
     "start_time": "2025-01-16T22:24:09.226317Z"
    }
   },
   "cell_type": "code",
   "source": "print(concat_str(train['table'][0], train['question'][0], train['answers'][0]))",
   "id": "ce2f8cb25de4c747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: | Year Division League Regular Season Playoffs Open Cup Avg. Attendance | 2001 2 USL A-League 4th, Western Quarterfinals Did not qualify 7,169 | 2002 2 USL A-League 2nd, Pacific 1st Round Did not qualify 6,260 | 2003 2 USL A-League 3rd, Pacific Did not qualify Did not qualify 5,871 | 2004 2 USL A-League 1st, Western Quarterfinals 4th Round 5,628 | 2005 2 USL First Division 5th Quarterfinals 4th Round 6,028 | 2006 2 USL First Division 11th Did not qualify 3rd Round 5,575 | 2007 2 USL First Division 2nd Semifinals 2nd Round 6,851 | 2008 2 USL First Division 11th Did not qualify 1st Round 8,567 | 2009 2 USL First Division 1st Semifinals 3rd Round 9,734 | 2010 2 USSF D-2 Pro League 3rd, USL (3rd) Quarterfinals 3rd Round 10,727 |\tQuestion: what was the last year where this team was a part of the usl a-league?\tAnswers:  | 2004 |\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:33:27.702453Z",
     "start_time": "2025-01-16T22:33:27.696441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SAVE_EPOCH = 10\n",
    "PATH_TO_train = 'train_str.txt'\n",
    "PATH_TO_test = 'test_str.txt'\n",
    "PATH_TO_eval = 'eval_str.txt'\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger('parse data')\n",
    "\n",
    "def dataset_parser(dataset, n) -> None:\n",
    "    train, test, eval = dataset['train'], dataset['test'], dataset['validation']\n",
    "    train_string = ''\n",
    "    test_string = ''\n",
    "    eval_string = ''\n",
    "    \n",
    "    logger.info('Begin to parse train data')\n",
    "    for i in tqdm(range(train.num_rows)):\n",
    "        train_string += concat_str(train['table'][i], train['question'][i], train['answers'][i])\n",
    "        train_string += '\\n'\n",
    "\n",
    "        \n",
    "        if i % SAVE_EPOCH == 0:\n",
    "            with open(f'{n}_{PATH_TO_train}', 'a', encoding='utf-8') as train_file:\n",
    "                train_file.write(train_string)\n",
    "            \n",
    "            train_string = ''\n",
    "    \n",
    "    with open(f'{n}_{PATH_TO_train}', 'a', encoding='utf-8') as train_file:\n",
    "        train_file.write(train_string)\n",
    "    logger.info('End to parse train data')\n",
    "    \n",
    "    logger.info('Begin to parse test data')\n",
    "    for i in tqdm(range(test.num_rows)):\n",
    "        test_string += concat_str(test['table'][i], test['question'][i], test['answers'][i], 'test')\n",
    "        test_string += '\\n'\n",
    "        \n",
    "        if i % SAVE_EPOCH == 0:\n",
    "            with open(f'{n}_{PATH_TO_test}', 'a', encoding='utf-8') as test_file:\n",
    "                test_file.write(test_string)\n",
    "                \n",
    "            test_string = ''\n",
    "\n",
    "    with open(f'{n}_{PATH_TO_test}', 'a', encoding='utf-8') as test_file:\n",
    "        test_file.write(test_string)\n",
    "    logger.info('End to parse test data')\n",
    "            \n",
    "    logger.info('Begin to parse eval data')\n",
    "    for i in tqdm(range(eval.num_rows)):\n",
    "        eval_string += concat_str(eval['table'][i], eval['question'][i], eval['answers'][i], 'eval')\n",
    "        eval_string += '\\n'\n",
    "        \n",
    "        if i % SAVE_EPOCH == 0:\n",
    "            with open(f'{n}_{PATH_TO_eval}', 'a', encoding='utf-8') as eval_file:\n",
    "                eval_file.write(eval_string)\n",
    "                \n",
    "            eval_string = ''\n",
    "            \n",
    "    with open(f'{n}_{PATH_TO_eval}', 'a', encoding='utf-8') as eval_file:\n",
    "        eval_file.write(eval_string)\n",
    "    logger.info('End to parse eval data')"
   ],
   "id": "3266021900b266e1",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:33:28.999019Z",
     "start_time": "2025-01-16T22:33:27.969022Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"wikitablequestions\", \"random-split-1\", trust_remote_code=True)",
   "id": "49f3bdde229ab4ea",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:40:39.392136Z",
     "start_time": "2025-01-16T22:34:28.875240Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_parser(dataset, 1)",
   "id": "f5de48a4d0b76811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:parse data:Begin to parse train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 164/11321 [06:10<7:00:02,  2.26s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[107], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdataset_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[103], line 17\u001B[0m, in \u001B[0;36mdataset_parser\u001B[1;34m(dataset, n)\u001B[0m\n\u001B[0;32m     15\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBegin to parse train data\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(train\u001B[38;5;241m.\u001B[39mnum_rows)):\n\u001B[1;32m---> 17\u001B[0m     train_string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m concat_str(\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[i], train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m'\u001B[39m][i], train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124manswers\u001B[39m\u001B[38;5;124m'\u001B[39m][i])\n\u001B[0;32m     18\u001B[0m     train_string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m SAVE_EPOCH \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2760\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2761\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\arrow_dataset.py:2747\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2745\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2746\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[1;32m-> 2747\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2748\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2749\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2750\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\formatting\\formatting.py:639\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\formatting\\formatting.py:405\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_row(pa_table)\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 405\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_batch(pa_table)\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\formatting\\formatting.py:448\u001B[0m, in \u001B[0;36mPythonFormatter.format_column\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[1;32m--> 448\u001B[0m     column \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_arrow_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    449\u001B[0m     column \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_features_decoder\u001B[38;5;241m.\u001B[39mdecode_column(column, pa_table\u001B[38;5;241m.\u001B[39mcolumn_names[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m column\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\datasets\\formatting\\formatting.py:148\u001B[0m, in \u001B[0;36mPythonArrowExtractor.extract_column\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[1;32m--> 148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpa_table\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pylist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\pyarrow\\table.pxi:1366\u001B[0m, in \u001B[0;36mpyarrow.lib.ChunkedArray.to_pylist\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\pyarrow\\array.pxi:1656\u001B[0m, in \u001B[0;36mpyarrow.lib.Array.to_pylist\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\pyvenvs\\dac\\Lib\\site-packages\\pyarrow\\scalar.pxi:794\u001B[0m, in \u001B[0;36mpyarrow.lib.StructScalar.as_py\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m<frozen _collections_abc>:788\u001B[0m, in \u001B[0;36mkeys\u001B[1;34m(self)\u001B[0m\n",
      "File \u001B[1;32m<frozen _collections_abc>:812\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, mapping)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77eab36c30ec2278"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
